{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0e0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "# load image from the IAM database\n",
    "url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-stage1')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-stage1')\n",
    "\n",
    "# training\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values  # Batch size 1\n",
    "decoder_input_ids = torch.tensor([[model.config.decoder.decoder_start_token_id]])\n",
    "outputs = model(pixel_values=pixel_values, decoder_input_ids=decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0971e010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=None, logits=tensor([[[-6.8819, -4.9600,  0.4070,  ..., -7.0768, -5.9763, -5.9058]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.2510,  0.3436, -0.2516,  ..., -0.9869,  0.0312,  0.3005],\n",
       "         [ 1.6950, -0.1244,  1.7893,  ...,  0.5487, -0.8726,  1.3767],\n",
       "         [ 0.8289, -0.7352,  1.6247,  ...,  0.6343, -1.8832,  1.1169],\n",
       "         ...,\n",
       "         [ 0.9176, -0.9133,  1.4384,  ...,  0.5853,  0.4590,  1.2997],\n",
       "         [-0.3422, -0.1819,  1.2618,  ...,  0.8715, -1.3387,  0.3654],\n",
       "         [ 0.6898,  0.2612,  1.4124,  ...,  0.8522, -1.6116,  1.2407]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d318d2d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.27.0-py3-none-any.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading orjson-3.8.10-cp39-cp39-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (482 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m482.6/482.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: requests in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (2.28.2)\n",
      "Requirement already satisfied: jinja2 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (2.1.2)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (9.5.0)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.1-cp39-cp39-macosx_11_0_arm64.whl (7.3 MB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx\n",
      "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (0.13.4)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: pandas in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (2.0.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (338 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.3/338.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: numpy in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio) (1.24.2)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client>=0.1.3\n",
      "  Downloading gradio_client-0.1.3-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.2/286.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting altair>=4.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from gradio-client>=0.1.3->gradio) (23.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from pandas->gradio) (2.8.2)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from aiohttp->gradio) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from aiohttp->gradio) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from httpx->gradio) (3.4)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp39-cp39-macosx_11_0_arm64.whl (229 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-macosx_11_0_arm64.whl (63 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from requests->gradio) (1.26.15)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.15.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=64e148e44976a6d9dc9bcf38dd8d29607b994103b40d3d23e88e8ef0daad1765\n",
      "  Stored in directory: /Users/arpitsharma/Library/Caches/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, toolz, semantic-version, python-multipart, pyparsing, pydantic, orjson, multidict, mdurl, kiwisolver, importlib-resources, h11, fsspec, frozenlist, fonttools, entrypoints, cycler, contourpy, click, async-timeout, aiofiles, yarl, uvicorn, starlette, matplotlib, markdown-it-py, linkify-it-py, httpcore, aiosignal, mdit-py-plugins, httpx, fastapi, altair, aiohttp, gradio-client, gradio\n",
      "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 altair-4.2.2 async-timeout-4.0.2 click-8.1.3 contourpy-1.0.7 cycler-0.11.0 entrypoints-0.4 fastapi-0.95.1 ffmpy-0.3.0 fonttools-4.39.3 frozenlist-1.3.3 fsspec-2023.4.0 gradio-3.27.0 gradio-client-0.1.3 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 importlib-resources-5.12.0 kiwisolver-1.4.4 linkify-it-py-2.0.0 markdown-it-py-2.2.0 matplotlib-3.7.1 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.0.4 orjson-3.8.10 pydantic-1.10.7 pydub-0.25.1 pyparsing-3.0.9 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.26.1 toolz-0.12.0 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.2 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501ed784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.weight', 'encoder.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages/gradio/inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-stage1\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-stage1\")\n",
    "# 2 cpu and 16gib ram\n",
    "def process_image(image):\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_text\n",
    "\n",
    "title = \"Transforme(encoder-decoder) based Text OCR\"\n",
    "description = \"Demo for Microsoft's TrOCR, an encoder-decoder model \\\n",
    "        consisting of an image Transformer encoder and a text Transformer \\\n",
    "        decoder for state-of-the-art optical character recognition (OCR) on \\\n",
    "        single-text line images. This particular model is fine-tuned on IAM, \\\n",
    "        a dataset of annotated handwritten images.\"\n",
    "article = \"<p style='text-align: center'><a href='https://arxiv.org/abs/2109.10282'>Transformer Optical Character Recognition with Pre-trained Models</a> | <a href='https://github.com/microsoft/unilm/tree/master/trocr'>Github Repo</a></p>\"\n",
    "\n",
    "url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=process_image, \n",
    "                     inputs=gr.inputs.Image(type=\"pil\"), \n",
    "                     outputs=gr.outputs.Textbox(),\n",
    "                     title=title,\n",
    "                     description=description,\n",
    "                     article=article)\n",
    "iface.launch(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43dcf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.weight', 'encoder.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-stage1\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-stage1\")\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f5fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"data/photo.png\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d9866b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitsharma/miniconda3/envs/vision/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = process_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795d332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3065'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88286c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
